#!/usr/bin/env python
"""
Batched Line Search Benchmark: Serial vs Batched optimization.

Compares the current serial backtracking line search (up to 10 sequential
kernel calls per iteration) against a batched approach that evaluates all
candidate step sizes in a SINGLE kernel call.

Backends: AADC Python and GPU (CUDA) only (no C++).

Usage:
    python benchmark_batched_linesearch.py --trades 1000 --portfolios 5 --threads 8
    python benchmark_batched_linesearch.py --trades 500 --portfolios 5 --method adam
    python benchmark_batched_linesearch.py --trades 1000 --portfolios 5 --ls-candidates 16

Version: 1.1.0
"""

MODEL_VERSION = "1.1.0"

import sys
import os
import time
import argparse
import numpy as np
import pandas as pd
from pathlib import Path
from datetime import datetime

sys.path.insert(0, str(Path(__file__).parent))

# Check AADC
try:
    import aadc
    AADC_AVAILABLE = True
except ImportError:
    AADC_AVAILABLE = False

# Check CUDA
CUDA_SIMULATOR = os.environ.get('NUMBA_ENABLE_CUDASIM', '0') == '1'
try:
    from numba import cuda
    CUDA_AVAILABLE = cuda.is_available() or CUDA_SIMULATOR
except ImportError:
    CUDA_AVAILABLE = False

# Reuse shared infrastructure from benchmark_trading_workflow
from benchmark_trading_workflow import (
    setup_portfolio_and_kernel,
    optimize_allocation,
    greedy_local_search,
    _eval_aadc,
    _eval_gpu,
    _make_aadc_grad_fn,
    _make_gpu_grad_fn,
    TeeWriter,
)
from model.batched_optimizer import optimize_allocation_batched
from benchmark_aadc_vs_gpu import _build_benchmark_log_row
from common.portfolio import LOG_COLUMNS

LOG_FILE_BATCHED = Path(__file__).parent / "data" / "execution_log_batched.csv"


def _write_log_batched(log_rows):
    """Append rows to data/execution_log_batched.csv (same schema as portfolio log)."""
    try:
        LOG_FILE_BATCHED.parent.mkdir(parents=True, exist_ok=True)
        df = pd.DataFrame(log_rows, columns=LOG_COLUMNS)
        if LOG_FILE_BATCHED.exists():
            existing_df = pd.read_csv(LOG_FILE_BATCHED, nrows=0)
            if set(existing_df.columns) != set(LOG_COLUMNS):
                existing_df = pd.read_csv(LOG_FILE_BATCHED)
                combined = pd.concat([existing_df, df], ignore_index=True)
                combined = combined.reindex(columns=LOG_COLUMNS)
                combined.to_csv(LOG_FILE_BATCHED, mode="w", header=True, index=False)
            else:
                df.to_csv(LOG_FILE_BATCHED, mode="a", header=False, index=False)
        else:
            df.to_csv(LOG_FILE_BATCHED, mode="w", header=True, index=False)
    except OSError as e:
        print(f"  Warning: could not write batched log: {e}")


def _fmt_time(t):
    if t is None:
        return "N/A"
    if t < 0.001:
        return f"{t*1e6:.0f} us"
    if t < 1.0:
        return f"{t*1000:.2f} ms"
    return f"{t:.3f} s"


def _make_clustered_allocation(T, P):
    """
    Block allocation: trades 0..T/P-1 → portfolio 0, etc.
    Since trades are generated by type in order (ir_swap, equity_option, fx_option),
    this clusters same-type trades into the same portfolios, creating a deliberately
    suboptimal starting point with concentrated risk and no cross-asset netting.
    """
    allocation = np.zeros((T, P), dtype=np.float64)
    block_size = max(1, T // P)
    for t in range(T):
        p = min(t // block_size, P - 1)
        allocation[t, p] = 1.0
    return allocation


def run_benchmark(
    num_trades=1000,
    num_portfolios=5,
    num_threads=8,
    optimize_iters=100,
    method="gradient_descent",
    ls_candidates=10,
    num_simm_buckets=3,
    trade_types=None,
    output_file=None,
    clustered=True,
):
    # Tee output
    tee = None
    if output_file:
        output_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), output_file)
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        tee = TeeWriter(output_path)
        sys.stdout = tee

    print("=" * 70)
    print("  Batched Line Search Benchmark: Serial vs Batched")
    print("=" * 70)

    if not AADC_AVAILABLE and not CUDA_AVAILABLE:
        print("\nERROR: No backends available (need AADC or CUDA).")
        if tee:
            tee.close()
        return None

    # Setup
    if trade_types is None:
        trade_types = ["ir_swap", "equity_option", "fx_option"]
    print(f"\n  Setting up portfolio (T={num_trades}x{len(trade_types)} types, P={num_portfolios})...")
    print(f"  Trade types: {', '.join(trade_types)}")
    ctx = setup_portfolio_and_kernel(
        num_trades, num_portfolios, trade_types, num_simm_buckets, num_threads
    )
    T, P, K, B = ctx["T"], ctx["P"], ctx["K"], ctx["B"]

    print(f"  S: {T} trades x {K} factors, {B} buckets")
    print(f"  Intra-bucket correlations: {ctx['active_corrs']} pairs")
    if AADC_AVAILABLE:
        print(f"  AADC Py kernel recording:  {ctx['rec_time']*1000:.2f} ms")
    print(f"  Method: {method}, LS candidates: {ls_candidates}, Iters: {optimize_iters}")
    print(f"  AADC: {'Yes' if AADC_AVAILABLE else 'No'}  "
          f"CUDA: {'Yes' if CUDA_AVAILABLE else 'No'}"
          f"{'  (simulator)' if CUDA_SIMULATOR else ''}")

    S = ctx["S"]
    if clustered and len(trade_types) > 1:
        allocation = _make_clustered_allocation(T, P)
        print(f"  Allocation: type-clustered (concentrated risk, suboptimal start)")
    else:
        allocation = ctx["initial_allocation"]
        print(f"  Allocation: random (seed=42)")

    # Quick diagnostic: initial IM and gradient stats
    diag_fn = _make_aadc_grad_fn(ctx) if AADC_AVAILABLE else _make_gpu_grad_fn(ctx)
    agg_init = np.dot(S.T, allocation).T  # (P, K)
    im_init, grad_init = diag_fn(agg_init)
    gradient_init = np.dot(S, grad_init.T)  # (T, P)
    grad_max = np.abs(gradient_init).max()
    grad_nz = np.count_nonzero(gradient_init)
    print(f"  Initial IM: ${np.sum(im_init):,.0f}  (per-portfolio range: "
          f"${np.min(im_init):,.0f} .. ${np.max(im_init):,.0f})")
    print(f"  Gradient: max={grad_max:.4e}, nonzero={grad_nz}/{gradient_init.size}, "
          f"mean_abs={np.abs(gradient_init).mean():.4e}")

    results = {}

    def _run_pipeline(label, grad_fn, is_serial):
        """Run Phase 1 (continuous) + Phase 2 (greedy) optimization pipeline."""
        tag = f"{label} {'serial' if is_serial else 'batched'}"
        t0 = time.perf_counter()

        # Phase 1: continuous relaxation
        if is_serial:
            phase1 = optimize_allocation(
                S, allocation, grad_fn,
                max_iters=optimize_iters, verbose=False, label=tag,
                method=method,
            )
        else:
            phase1 = optimize_allocation_batched(
                S, allocation, grad_fn,
                max_iters=optimize_iters, verbose=False, label=tag,
                method=method, ls_candidates=ls_candidates,
            )

        # Phase 2: greedy local search on rounded integer allocation
        greedy = greedy_local_search(
            S, phase1['final_allocation'], grad_fn,
            max_rounds=50, verbose=False, label=tag,
        )

        wall_time = time.perf_counter() - t0

        # Merge: use greedy result if it improved
        final_im = min(phase1['final_im'], greedy['final_im'])
        final_alloc = greedy['final_allocation'] if greedy['final_im'] < phase1['final_im'] else phase1['final_allocation']
        trades_moved = int(np.sum(
            np.argmax(final_alloc, axis=1) != np.argmax(allocation, axis=1)
        ))
        total_evals = phase1['num_evals'] + greedy['num_evals']

        return {
            'final_allocation': final_alloc,
            'final_im': final_im,
            'initial_im': phase1['initial_im'],
            'im_history': phase1['im_history'] + greedy['im_history'],
            'num_iterations': phase1.get('num_iterations', 0),
            'num_evals': total_evals,
            'num_ls_evals': phase1.get('num_ls_evals', 0),
            'eval_time': wall_time,
            'grad_time': phase1.get('grad_time', 0),
            'trades_moved': trades_moved,
            'phase1_im': phase1['final_im'],
            'greedy_im': greedy['final_im'],
            'greedy_evals': greedy['num_evals'],
        }

    def _print_backend_results(backend_label, serial_res, batched_res):
        serial_reduction = (serial_res['initial_im'] - serial_res['final_im']) / serial_res['initial_im'] * 100
        batched_reduction = (batched_res['initial_im'] - batched_res['final_im']) / batched_res['initial_im'] * 100
        speedup = serial_res['eval_time'] / batched_res['eval_time'] if batched_res['eval_time'] > 0 else 0

        print(f"\n  {'Method':<20} {'Wall Time':>12} {'Evals':>7} {'Final IM':>18} {'Reduction':>10}")
        print(f"  {'-'*20} {'-'*12} {'-'*7} {'-'*18} {'-'*10}")
        print(f"  {'Serial ' + method:<20} {_fmt_time(serial_res['eval_time']):>12} "
              f"{serial_res['num_evals']:>7} ${serial_res['final_im']:>16,.0f} "
              f"{serial_reduction:>9.1f}%")
        print(f"  {'Batched ' + method:<20} {_fmt_time(batched_res['eval_time']):>12} "
              f"{batched_res['num_evals']:>7} ${batched_res['final_im']:>16,.0f} "
              f"{batched_reduction:>9.1f}%")
        print(f"\n  Speedup: {speedup:.2f}x")
        print(f"  Serial:  {serial_res['num_iterations']} iters + greedy → "
              f"{serial_res['trades_moved']} trades moved "
              f"(phase1 ${serial_res['phase1_im']:,.0f}, greedy ${serial_res['greedy_im']:,.0f})")
        print(f"  Batched: {batched_res['num_iterations']} iters + greedy → "
              f"{batched_res['trades_moved']} trades moved "
              f"(phase1 ${batched_res['phase1_im']:,.0f}, greedy ${batched_res['greedy_im']:,.0f})")
        return speedup

    # --- AADC Python ---
    if AADC_AVAILABLE:
        grad_fn = _make_aadc_grad_fn(ctx)

        print(f"\n  {'='*60}")
        print(f"  AADC Python")
        print(f"  {'='*60}")

        print(f"  Running serial {method} + greedy...")
        serial_res = _run_pipeline("AADC", grad_fn, is_serial=True)

        print(f"  Running batched {method} (ls_candidates={ls_candidates}) + greedy...")
        batched_res = _run_pipeline("AADC", grad_fn, is_serial=False)

        speedup = _print_backend_results("AADC Py", serial_res, batched_res)
        results["aadc"] = {
            "serial": serial_res, "batched": batched_res, "speedup": speedup,
        }

    # --- GPU (CUDA) ---
    if CUDA_AVAILABLE:
        grad_fn = _make_gpu_grad_fn(ctx)

        print(f"\n  {'='*60}")
        print(f"  GPU (CUDA)")
        print(f"  {'='*60}")

        print(f"  Running serial {method} + greedy...")
        serial_res = _run_pipeline("GPU", grad_fn, is_serial=True)

        print(f"  Running batched {method} (ls_candidates={ls_candidates}) + greedy...")
        batched_res = _run_pipeline("GPU", grad_fn, is_serial=False)

        speedup = _print_backend_results("GPU", serial_res, batched_res)
        results["gpu"] = {
            "serial": serial_res, "batched": batched_res, "speedup": speedup,
        }

    # --- Cross-backend summary ---
    if len(results) > 1:
        print(f"\n  {'='*60}")
        print(f"  Cross-Backend Summary")
        print(f"  {'='*60}")
        print(f"  {'Backend':<15} {'Serial':>12} {'Batched':>12} {'Speedup':>10}")
        print(f"  {'-'*15} {'-'*12} {'-'*12} {'-'*10}")
        for backend, r in results.items():
            label = "AADC Py" if backend == "aadc" else "GPU"
            print(f"  {label:<15} {_fmt_time(r['serial']['eval_time']):>12} "
                  f"{_fmt_time(r['batched']['eval_time']):>12} "
                  f"{r['speedup']:>9.2f}x")

    # --- Logging ---
    timestamp = datetime.now().isoformat()
    trade_types_str = ",".join(trade_types)
    common = dict(
        timestamp=timestamp,
        trade_types_str=trade_types_str,
        num_trades=T,
        num_simm_buckets=num_simm_buckets,
        num_portfolios=P,
        num_risk_factors=K,
        crif_time_sec=ctx.get("crif_time", 0),
    )
    log_rows = []

    for backend, r in results.items():
        backend_label = "aadc_py" if backend == "aadc" else "gpu"
        threads = num_threads if backend == "aadc" else 1

        for variant, res in [("serial", r["serial"]), ("batched", r["batched"])]:
            opt_res = dict(res)
            opt_res["max_iters"] = optimize_iters
            row = _build_benchmark_log_row(
                model_name=f"batched_ls_{variant}_{backend_label}",
                model_version=MODEL_VERSION,
                num_threads=threads,
                im_result=res["initial_im"],
                eval_time_sec=res["eval_time"],
                kernel_recording_sec=ctx.get("rec_time") if backend == "aadc" else None,
                optimize_result=opt_res,
                **common,
            )
            row["optimize_method"] = method
            log_rows.append(row)

    if log_rows:
        _write_log_batched(log_rows)
        print(f"\n  Logged {len(log_rows)} rows to {LOG_FILE_BATCHED}")

    print(f"\n{'='*70}")
    print(f"  Done.")
    print(f"{'='*70}")

    if tee:
        print(f"\n  Output saved to {output_path}")
        tee.close()

    return results


def main():
    parser = argparse.ArgumentParser(
        description="Batched Line Search Benchmark: Serial vs Batched (AADC Py + GPU)"
    )
    parser.add_argument('--trades', '-t', type=int, default=1000)
    parser.add_argument('--portfolios', '-p', type=int, default=5)
    parser.add_argument('--threads', type=int, default=8)
    parser.add_argument('--optimize-iters', type=int, default=100)
    parser.add_argument('--method', choices=['gradient_descent', 'adam'], default='gradient_descent')
    parser.add_argument('--ls-candidates', type=int, default=10,
                        help='Number of step sizes to evaluate in parallel (default 10)')
    parser.add_argument('--simm-buckets', type=int, default=3)
    parser.add_argument('--trade-types', type=str, default='ir_swap,equity_option,fx_option',
                        help='Comma-separated trade types (ir_swap,equity_option,fx_option,inflation_swap,xccy_swap)')
    parser.add_argument('--clustered', action='store_true', default=True,
                        help='Use type-clustered initial allocation (suboptimal start, default)')
    parser.add_argument('--random-alloc', action='store_true', default=False,
                        help='Use random initial allocation instead of clustered')
    parser.add_argument('--output', '-o', type=str, default='auto',
                        help='Output file (default: auto in data/). Use "none" to disable.')

    args = parser.parse_args()

    if args.output == 'none':
        output_file = None
    elif args.output == 'auto':
        ts = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_file = f"data/benchmark_batched_ls_{ts}.txt"
    else:
        output_file = args.output

    trade_types = [t.strip() for t in args.trade_types.split(',')]

    run_benchmark(
        num_trades=args.trades,
        num_portfolios=args.portfolios,
        num_threads=args.threads,
        optimize_iters=args.optimize_iters,
        method=args.method,
        ls_candidates=args.ls_candidates,
        num_simm_buckets=args.simm_buckets,
        trade_types=trade_types,
        output_file=output_file,
        clustered=not args.random_alloc,
    )


if __name__ == '__main__':
    main()
