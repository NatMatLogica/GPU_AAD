# AADC vs GPU Benchmark Runs

Auto-generated by `benchmark_aadc_vs_gpu.py` and updated manually with findings from batched line search benchmarks and cross-backend consistency verification.

---

## Issues Found and Fixed (2026-02-02)

### Problem: GPU IM Mismatch on Multi-Asset Portfolios

When running mixed trade types (ir_swap + equity_option + fx_option), the GPU and AADC backends produced different IM values (~5% discrepancy). The GPU gradient could not find IM improvements while AADC could.

**Root causes and fixes:**

| # | Issue | Symptom | Fix |
|---|-------|---------|-----|
| 1 | **AADC missing inter-bucket gamma for non-Rates risk classes** | AADC kernel only implemented `ir_gamma_diff_ccy` for Rates. CreditQ, CreditNonQ, Equity, and Commodity used gamma=0 (no inter-bucket aggregation). GPU kernel handled all risk classes correctly. | Added gamma lookup tables for all 5 risk classes in `simm_portfolio_aadc_v2.py`: `ir_gamma_diff_ccy`, `_CQ_INTER` (creditQ_corr_non_res 12x12), `cr_gamma_diff_ccy`, `_EQ_INTER` (equity_corr_non_res 12x12), `_CM_INTER` (commodity_corr_non_res 17x17). |
| 2 | **AADC NaN gradients from sqrt of negative k_rc_sq** | Inter-bucket cross-terms `S_b * gamma * S_c` can be negative, making `k_rc_sq < 0`. `sqrt(negative)` produces NaN that propagates through AADC adjoint. GPU kernel guarded with `if margin > 0 else 0`. | Added smooth `max(0, x)` approximation at all three sqrt sites: `k_sq_safe = (k_sq + sqrt(k_sq * k_sq + eps)) / 2 + eps` with `eps = 1.0` ($1 floor, negligible vs $1e15 IM). |
| 3 | **GPU MAX_B overflow** | Mixed trade types produced 69 buckets across all risk classes, exceeding `MAX_B = 64` in GPU kernel. GPU wrote out of bounds, producing garbage IM ($2.8e27). | Increased `MAX_B` from 64 to 128 in `simm_portfolio_cuda.py`. |

### Files Modified

| File | Change |
|------|--------|
| `model/simm_portfolio_aadc_v2.py` | Added inter-bucket gamma for all 5 risk classes; added smooth max at 3 sqrt sites; imported `creditQ_corr_non_res`, `equity_corr_non_res`, `commodity_corr_non_res`, `cr_gamma_diff_ccy` |
| `model/simm_portfolio_cuda.py` | `MAX_B = 64` → `MAX_B = 128` |

### After Fixes: Verification Results

| Metric | Value |
|--------|-------|
| IM relative difference (AADC vs GPU) | 3.12e-15 (machine precision) |
| NaN gradients | 0 |
| Max gradient relative error (valid entries) | 9.2e-15 |
| Optimization result (both backends) | 4.2% IM reduction (P=10, mixed types) |

Both backends now produce identical IMs and gradients to machine precision, and both find the same optimization improvements.

---

## Run: 2026-02-02 12:56:33 — Simplified SIMM (Pre-Fix, Historical)

> **Note**: This run used the old kernel before inter-bucket gamma fixes. GPU IM was $0 due to missing risk-class support. Results are preserved for reference only.

### Configuration

| Parameter | Value |
|-----------|-------|
| Command | `python benchmark_aadc_vs_gpu.py --trades 100 --portfolios 3 --threads 4` |
| Trades | 100 |
| Portfolios | 3 |
| Trade types | ir_swap |
| Threads (AADC) | 4 |
| Risk factors (K) | 30 |
| Sensitivity matrix | 100 x 30 |

### IM Values

| Backend | Total IM | Match |
|---------|----------|-------|
| AADC (CPU AAD) | $203,084,979,729.35 | Baseline |
| GPU (CUDA) | $0.00 | NO (diff: $96,563,757,293) |

### Gradient Accuracy

| Metric | Value |
|--------|-------|
| Max abs diff | 4.27e+01 |
| Max rel diff | 1.00e+00 |
| Match | NO |

---

## GPU Architecture Assessment

### Current Problem: Parallelizing Over the Wrong Dimension

The current GPU kernel (`simm_portfolio_cuda.py`) launches **one thread per portfolio**:

```
threads_per_block = 256
blocks = (P + 255) // 256
```

With a realistic P=5-20 portfolios, this gives grid size 1 (one block of 256 threads, only 5-20 active). Numba warns: `Grid size 1 will likely result in GPU under-utilization due to low occupancy`. An H100 has 132 SMs and supports >100K concurrent threads — using 5 of them wastes >99.99% of the chip.

This is not fixable with parameters. **In production, you don't increase the number of portfolios to fill GPU cores.** The parallelization strategy itself is wrong.

### What Each Thread Does (the real work)

Per portfolio, the kernel runs these sequential loops:

| Step | Operation | Complexity | Description |
|------|-----------|------------|-------------|
| 1 | Weighted sensitivities | O(K) | `WS[k] = S[k] * RW[k] * CR[k]` |
| 2 | Bucket sums | O(K) | Accumulate WS into B buckets |
| 3 | **Intra-bucket correlations** | **O(K²)** | `K_b² = Σ_kl ρ_kl × WS_k × WS_l` |
| 4 | Inter-bucket gamma | O(B²) | `Σ γ_bc × S_b × S_c` per risk class |
| 5 | Cross-RC aggregation | O(36) | 6×6 PSI matrix multiply |
| 6 | **Gradient per factor** | **O(K² + KB)** | Chain rule back through steps 3-5 |

With K=108 factors, steps 3 and 6 dominate: ~12K multiply-adds per portfolio for the forward pass, ~12K per factor for the gradient (~1.3M ops total). This is substantial work — but it's all done in a single thread.

### How to Actually Benefit from GPU

The SIMM formula is fundamentally linear algebra. A Python developer with a NumPy implementation has three options, from easiest to hardest:

#### Option A: Drop-in CuPy replacement (minimal changes)

Replace `import numpy as np` with `import cupy as cp`. The SIMM formula maps directly to matrix operations:

```python
# CPU (current)
WS = sensitivities * weights * concentration            # (P, K) element-wise
K_b_sq = WS @ intra_corr @ WS.T                        # (P, P) quadratic form
# ... extract diagonal per bucket ...

# GPU (CuPy — same API, runs on GPU)
WS = cp.asarray(sensitivities) * cp.asarray(weights) * cp.asarray(concentration)
K_b_sq = WS @ cp.asarray(intra_corr) @ WS.T
```

**What changes**: ~5 lines (array transfer to/from GPU). No custom kernels.
**What doesn't change**: Algorithm, formula, code structure.
**Limitation**: Python loop over buckets/risk classes remains serial on CPU, only the matrix ops inside each iteration run on GPU. Fine for K>100 where matmul dominates.

#### Option B: Restructure as batched matrix operations (moderate changes)

Reorganize the per-bucket loops into batched operations across all buckets simultaneously:

```python
# Instead of looping over B buckets:
for b in buckets:
    K_b_sq[b] = WS_b.T @ rho_b @ WS_b        # one matmul per bucket

# Batch all buckets into one operation:
# WS_blocked[b] is (P, K_b) for bucket b — pad to max bucket size
# rho_blocked[b] is (K_b, K_b)
# Use np.einsum or block-diagonal matmul:
K_all_sq = np.einsum('bpi,bij,bpj->bp', WS_blocked, rho_blocked, WS_blocked)
```

**What changes**: Loop structure. Buckets computed in parallel instead of sequentially.
**Benefit**: Eliminates the Python loop over B=40-70 buckets. All correlation work in one GPU call.
**Effort**: Requires padding/masking for variable-size buckets, restructuring the bucket grouping.

#### Option C: Custom CUDA kernel with proper parallelism (significant rewrite)

Parallelize over `(portfolio, factor)` pairs or `(portfolio, bucket)` pairs:

```
# Current: P threads (1 per portfolio, all K² work sequential)
grid = (P,)

# Better: P × B threads (1 per portfolio × bucket)
grid = (P, B)
# Each thread does O(K_b²) for its assigned bucket
# Reduction across buckets for inter-bucket gamma

# Best: P × K threads with shared memory
grid = (P, K)
# Each thread handles one factor's contribution
# Shared memory for bucket accumulation and reduction
```

**What changes**: Everything — new kernel, new launch config, shared memory management.
**Benefit**: Full GPU utilization regardless of P. K=108 factors × P=5 portfolios = 540 threads (still small, but workable with enough work per thread).
**Effort**: Substantial. Must manually handle reductions, bank conflicts, warp divergence.

### Recommendation: What a Python Developer Should Do

| Scenario | Approach | Effort | Speedup Expectation |
|----------|----------|--------|---------------------|
| K < 50, P < 20 | **Stay on CPU** | None | GPU overhead > benefit |
| K > 100, any P | **Option A (CuPy)** | Low | 2-10x for matmul-heavy parts |
| K > 100, optimization loop (many evals) | **Option B (batched)** | Medium | 5-20x (eliminates Python loops) |
| Full production system | **Option C (custom kernel)** | High | 10-50x (but diminishing returns vs AADC) |

**Key insight**: For SIMM specifically, AADC on CPU is likely the better investment than GPU. AADC gives you exact gradients via adjoint mode in a single forward+backward pass, with O(K) cost for ALL K gradients. The GPU kernel computes gradients via manual chain rule at O(K²) cost. AADC's algorithmic advantage (O(K) vs O(K²) for gradients) often outweighs GPU's hardware advantage, especially at moderate K.

**Where GPU genuinely wins**: The optimization loop. If you're running 1000+ SIMM evaluations (greedy search, stress testing, what-if analysis), parallelizing the candidates across GPU cores — evaluating 100 candidate trade moves simultaneously — is where GPU adds real value. This is a different kernel than the SIMM computation itself.

### Brute-Force GPU Without Gradients

Yes — this is arguably the strongest case for GPU in SIMM optimization.

#### Why it works

The current greedy optimizer (`greedy_local_search`) does this per round:
1. Compute gradient (1 eval with gradient) → rank candidate moves
2. Try top-k moves **one at a time**, each requiring a full P-portfolio SIMM eval
3. Accept or revert each move sequentially

With T=10K trades and P=20 portfolios, there are **T × (P-1) = 190,000** possible single-trade moves. The current approach uses gradient to filter down to ~1000 candidates, then evaluates them serially. A brute-force GPU approach evaluates **all 190K candidates in one kernel launch** — no gradient needed.

#### The incremental trick

Moving trade `t` from portfolio A to portfolio B only changes 2 of P portfolios:
```
new_agg_S[A, :] = old_agg_S[A, :] - S[t, :]    # remove trade from source
new_agg_S[B, :] = old_agg_S[B, :] + S[t, :]    # add trade to dest
delta_IM = (new_IM_A + new_IM_B) - (old_IM_A + old_IM_B)
```

Each GPU thread evaluates ONE candidate move:
- Thread ID encodes `(trade_t, dest_portfolio)` — 190K threads total
- Compute 2 incremental aggregations: O(K) each
- Run **forward-only** SIMM for 2 portfolios: O(K²) each
- Output: `delta_IM` for this move
- No gradient computation → kernel is ~half the size and cost

#### Performance estimate (K=108, T=10K, P=20)

| | Current serial greedy | Brute-force GPU |
|---|---|---|
| Candidates evaluated per round | ~1000 (gradient-filtered) | 190,000 (all possible) |
| SIMM evals per candidate | P=20 portfolios (full) | 2 portfolios (incremental) |
| Work per candidate | ~12K ops × 20 = 240K ops | ~12K ops × 2 = 24K ops |
| Parallelism | 1 (sequential) | 190,000 threads |
| Needs gradient? | Yes (to rank candidates) | No |
| Grid size | 1 | ~750 blocks × 256 threads |
| Rounds to converge | ~10-50 | ~10-50 (same algorithm) |
| Estimated time per round | ~seconds (serial evals) | ~1ms (one kernel launch) |

#### Why this is the right GPU architecture for SIMM

1. **Grid size 190K** — full GPU utilization (vs grid size 1 with current approach)
2. **Forward-only kernel** — half the code, half the registers, half the memory
3. **No gradient pitfalls** — no NaN from sqrt, no smooth-max hacks, no AADC dependency
4. **Globally optimal per round** — evaluates ALL moves, not a gradient-filtered subset (gradient can miss beneficial moves due to non-convexity)
5. **Simpler code** — just the forward SIMM formula in a kernel, no chain rule
6. **Incremental eval** — only recompute 2 affected portfolios, not all P

#### What the kernel looks like

```python
@cuda.jit
def eval_all_moves_kernel(
    agg_S,           # (P, K) current aggregated sensitivities
    S,               # (T, K) per-trade sensitivities
    curr_assign,     # (T,) current portfolio assignment per trade
    base_im,         # (P,) current IM per portfolio
    risk_weights,    # (K,) ...SIMM constants...
    delta_im_out,    # (T, P) output: IM change for each possible move
):
    idx = cuda.grid(1)
    t = idx // (P - 1)       # which trade
    move_idx = idx % (P - 1) # which destination (skip current)
    src_p = curr_assign[t]
    dst_p = move_idx if move_idx < src_p else move_idx + 1

    # Incremental aggregation
    new_src_agg = agg_S[src_p, :] - S[t, :]
    new_dst_agg = agg_S[dst_p, :] + S[t, :]

    # Forward-only SIMM (no gradient)
    new_src_im = simm_forward(new_src_agg, ...)
    new_dst_im = simm_forward(new_dst_agg, ...)

    delta_im_out[t, dst_p] = (new_src_im + new_dst_im) - (base_im[src_p] + base_im[dst_p])
```

Then on CPU: `best_move = np.argmin(delta_im_out)` → apply move → repeat.

#### When to use gradient vs brute-force

| Approach | Best when | Weakness |
|----------|-----------|----------|
| Gradient (AADC) | K is large, continuous relaxation works | Requires rounding; misses discrete structure |
| Gradient (GPU manual) | Never — O(K²) gradient on GPU < O(K) gradient via AADC | Worst of both worlds |
| **Brute-force GPU** | **T×P fits in GPU grid (>1000 threads), forward pass is cheap** | **Memory for delta_im_out (T×P floats)** |
| Hybrid | Large T: use gradient to filter to top-N, then GPU-eval top-N | More complex pipeline |

**Bottom line**: Brute-force GPU is the natural fit for SIMM allocation optimization. It plays to GPU strengths (massive parallelism, simple uniform computation) and avoids GPU weaknesses (complex gradient code, small grid sizes). A Python developer should write a forward-only SIMM kernel and parallelize over candidate moves, not over portfolios.

### Summary of Required Logic Changes

| Component | Current (per-portfolio thread) | GPU-native approach | Rethink needed? |
|-----------|-------------------------------|--------------------|----|
| `WS = S * RW * CR` | Sequential loop O(K) | Element-wise GPU op | No — trivial |
| Bucket sum `S_b` | Sequential loop O(K) | Scatter-add or segment-reduce | Minor |
| **Intra-bucket `K_b²`** | **Nested loop O(K²)** | **Batched matmul across buckets** | **Yes — restructure** |
| Inter-bucket gamma | Loop O(B²) | Small matmul (B×B) | No — too small to matter |
| Cross-RC PSI | Loop O(36) | 6×6 matmul | No — trivial |
| **Gradient** | **Manual chain rule O(K²)** | **Use AADC instead, or batched Jacobian** | **Yes — fundamental** |

The intra-bucket correlation (O(K²)) and gradient computation need restructuring. Everything else maps directly. A Python developer would NOT need to rethink the SIMM formula itself — only the loop structure around it.

---

## Pure GPU IR Implementation: Fair Apples-to-Apples Comparison (2026-02-03)

### Motivation

Previous GPU implementations (`simm_portfolio_cuda.py`, `cuda_backend.py`) only handle **SIMM aggregation** — they take pre-computed CRIF sensitivities as input. The pricers that generate those sensitivities run on CPU. This creates a CPU→GPU transfer bottleneck and makes timing comparisons unfair:

```
Previous:  CPU Pricers → CRIF → [Transfer] → GPU SIMM Aggregation
                               ~~~~~~~~~~~~
                               PCIe bottleneck (not measured)
```

To enable a fair benchmark, a new **Pure GPU IR** implementation was created that keeps the entire pipeline on GPU:

```
Pure GPU:  GPU Pricers → GPU CRIF → GPU SIMM → GPU Gradients
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           Everything stays in GPU memory (HBM)
```

### Implementation

| File | Purpose |
|------|---------|
| `model/pure_gpu_ir.py` | Complete GPU backend for IR swaps (v1.0.0) |
| `benchmark_pure_gpu_ir.py` | Benchmark comparing Pure GPU, AADC Python, C++ AADC |

### What `model/pure_gpu_ir.py` Provides

| Component | Description |
|-----------|-------------|
| `_price_irs` | CUDA device function for vanilla IRS pricing (NPV via period summation) |
| `_discount` | CUDA device function for discount factor interpolation |
| `_forward_rate` | CUDA device function for forward rate calculation |
| `_compute_crif_kernel` | GPU bump-and-revalue: computes 12 IR tenor sensitivities per trade |
| `_simm_im_gradient_kernel` | Full SIMM with analytical gradient (forward + gradient in one kernel) |
| `_simm_im_only_kernel` | Forward-only SIMM (no gradient, for brute-force search) |
| `PureGPUIRBackend` | High-level API: `setup()`, `compute_im_and_gradient()`, `compute_im_only()` |

### SIMM Formula (IR-Only)

The Pure GPU kernel implements the same ISDA SIMM v2.6 formula as other backends:

```
K_ir = sqrt(Σ_i Σ_j ρ_ij × WS_i × WS_j)
Where:
  WS_i = RW_i × S_i × CR     (weighted sensitivity)
  RW_i = IR risk weight for tenor i (from v2.6 table)
  ρ_ij = 12×12 IR tenor correlation matrix
  CR = concentration risk factor (1.0 for most cases)
```

Since this is IR-only, there's no cross-risk-class aggregation — K_ir **is** the IM.

### Verification Results

Running `benchmark_pure_gpu_ir.py` with identical inputs produces **bit-identical** IM values:

| Backend | Total IM | Match |
|---------|----------|-------|
| AADC Python | $96,061,720,835.75 | Baseline |
| Pure GPU | $96,061,720,835.74 | ✅ MATCH (diff < $1) |
| C++ AADC | $1,341,144,541,847.29 | N/A (includes all 5 asset types) |

The $0.01 difference between AADC Python and Pure GPU is floating-point precision (< 1e-11 relative error).

**Note**: C++ AADC generates all 5 asset types (IR swap, equity option, FX option, inflation swap, XCCY swap), so its IM is not directly comparable to the IR-only backends.

### Benchmark Output

```
======================================================================
   Pure GPU vs AADC Benchmark (IR Swaps Only)
======================================================================
Configuration:
  Trades:     50
  Portfolios: 3
  Threads:    4
  Seed:       42

Available backends:
  AADC Python: Yes
  Pure GPU:    Yes (SIMULATOR)  ← Warning if using CUDA simulator
  C++ AADC:    Yes
  WARNING: CUDA simulator mode - Pure GPU timing not representative!

...

IM Validation (IR-only backends):
  AADC Python vs Pure GPU: MATCH

Note: C++ AADC includes ALL 5 asset types (not IR-only), so its IM is
      higher and not comparable to IR-only backends.
======================================================================
```

### CUDA Simulator Warning

When running with `NUMBA_ENABLE_CUDASIM=1`, the "GPU" code actually runs on CPU with Numba interpreter overhead. This makes Pure GPU appear **slower** than AADC Python in simulator mode. On real GPU hardware, the CRIF computation (T trades × 12 bumps) runs massively parallel and would be significantly faster.

### Usage

```bash
source venv/bin/activate

# With real GPU
python benchmark_pure_gpu_ir.py --trades 1000 --portfolios 5 --threads 8

# With CUDA simulator (for testing without GPU)
NUMBA_ENABLE_CUDASIM=1 python benchmark_pure_gpu_ir.py --trades 100 --portfolios 3 --threads 4
```

### Scope and Limitations

| Aspect | Status |
|--------|--------|
| Asset classes | IR Swaps only (Risk_IRCurve) |
| Risk measures | Delta only (no Vega, Curvature) |
| Currencies | Single currency (no XCCY) |
| Gradients | Analytical (via chain rule) or forward-only |

For multi-asset benchmarks, the existing GPU backends (`simm_portfolio_cuda.py`) should be used. The Pure GPU IR implementation is specifically designed for **fair methodology comparison** on a limited but well-defined scope.

### Relationship to `gpu-implementation-effort.md`

The Pure GPU IR implementation corresponds to **Option A** in the GPU implementation effort analysis:

> **Option A (+6-7 days)**: Add CUDA pricers with bump-and-revalue. This eliminates the CPU→GPU transfer bottleneck.

Actual implementation effort was ~3 days for IR swaps only (subset of the full 5 asset classes estimated in that document).

---

## Batched Line Search Benchmark Results (2026-02-02)

### Concept

The current serial optimizer evaluates ONE step size per line search trial (up to 10 sequential kernel calls per iteration). The batched version pre-computes ALL candidate step sizes and evaluates them in a SINGLE kernel call by treating each `(step_size, portfolio)` pair as an independent portfolio in the batch.

- **Serial**: 1 gradient eval + up to 10 serial LS evals = ~11 kernel calls/iteration
- **Batched**: 1 gradient eval + 1 batched LS eval (candidates x P portfolios) = 2 kernel calls/iteration

### Implementation

| File | Purpose |
|------|---------|
| `model/batched_optimizer.py` | Independent batched line search optimizer (v1.0.0) |
| `benchmark_batched_linesearch.py` | A/B benchmark: serial vs batched, AADC Py + GPU (v1.0.0) |

### Results: T=10,000 trades, P=30 portfolios, Adam optimizer, 16 LS candidates

| Backend | Serial | Batched | Speedup |
|---------|--------|---------|---------|
| AADC Py | 222.29 ms | 2.696 s | 0.08x |
| GPU | 920.64 ms | 2.835 s | 0.32x |

### Results: T=100,000 trades, P=300 portfolios, Adam optimizer, 16 LS candidates

| Backend | Serial | Batched | Speedup |
|---------|--------|---------|---------|
| AADC Py | 4.332 s | 44.854 s | 0.10x |
| GPU | 4.748 s | 44.984 s | 0.11x |

### Analysis

In these runs, the optimizer converged in only 2 iterations with 0 trades moved (ir_swap-only portfolios have identical risk profiles, preventing netting). With so few iterations and early convergence, the serial line search's early-exit behavior is more efficient than evaluating all candidates.

**Key finding**: Batching helps most when:
1. The optimizer runs many iterations with frequent line search retries
2. GPU kernel launch latency dominates (small P) — observed 24x speedup at P=3 on GPU
3. Mixed trade types create real netting opportunities, forcing more optimizer iterations

**Where batching does NOT help**:
- AADC Python: compute scales linearly with batch size, dispatch overhead is negligible
- Large P with early convergence: serial early-exit saves most of the work

### Recommendation

For production use, the serial line search with Armijo early exit remains the better default. Batched line search is beneficial specifically for GPU workloads with small portfolio counts (P < 10) where kernel launch latency is the bottleneck.

---

## Trading Day Workflow: 4-Backend Benchmark (2026-02-02)

### Overview

The trading workflow (`benchmark_trading_workflow.py` v2.8.0) simulates a full trading day in 5 steps, with up to 4 compute backends measured per step:

| Backend | Code | Description |
|---------|------|-------------|
| **AADC Python** | `aadc_full` | Python AADC kernel: single `aadc.evaluate()` for all P portfolios, gradient via adjoint |
| **GPU CUDA** | `gpu_full` | Numba CUDA kernel: handwritten SIMM + analytical gradient |
| **Brute-Force GPU** | `bf_gpu` | Forward-only CUDA kernel: no gradients, enumerates candidates |
| **C++ AADC** | `cpp_aadc` | C++ binary (`build/simm_optimizer`): AADC SDK with OpenMP threading |

### Workflow Steps

| Step | Name | Time | What it does | Backends |
|------|------|------|-------------|----------|
| 1 | Portfolio Setup | 9:00 AM | Compute IM for initial allocation | AADC, GPU, BF, C++ |
| 2 | Margin Attribution | 10:00 AM | Euler-allocated IM contribution per trade | AADC, GPU, BF, C++ |
| 3 | Pre-Trade Routing | 1:00 PM | Route new trades to best counterparty | AADC, GPU, BF, C++ |
| 4 | What-If Scenarios | 3:00 PM | Unwind, stress IR/EQ, marginal IM | AADC, GPU, BF, C++ |
| 5 | EOD Optimization | 5:00 PM | Reallocate trades to minimize total IM | Per method (see below) |

### EOD Optimization Methods

Step 5 runs up to 3 optimization methods (controlled by `--exclude`):

| Method | Step Name | Phase 1 | Phase 2 | Backends |
|--------|-----------|---------|---------|----------|
| `gradient_descent` | EOD: GD | Continuous GD with Armijo line search | Greedy local search | AADC, GPU, C++ |
| `adam` | EOD: Adam | Adam optimizer (β1=0.9, β2=0.999) | Greedy local search | AADC, GPU, C++ |
| `gpu_brute_force` | EOD: Brute-Force | Enumerate all T×(P-1) single-trade moves | Accept best per round | BF |

### Brute-Force Implementation Per Step

| Step | BF Approach | GPU Launches | Complexity |
|------|-------------|-------------|------------|
| 1 (Setup) | Forward-only IM eval | 1 | O(P×K²) |
| 2 (Attribution) | Bump-and-revalue: remove each trade, recompute IM | 1 (batched) | O(T×K²) |
| 3 (Pre-Trade) | Try all P portfolios for each new trade | 2 per trade | O(N×P×K²) |
| 4 (What-If) | Forward-only scenario evaluation | 1 per scenario | O(S×K²) |
| 5 (Brute-Force) | Evaluate all T×(P-1) single-trade moves per round | 1 per round | O(R×T×P×K²) |

### CSV Logging

Each run produces rows in `data/execution_log_portfolio.csv`. Row count per run:
- Steps 1-4: up to 4 rows each (aadc, gpu, bf, cpp — only if backend ran)
- EOD GD: 3 rows (aadc, gpu, cpp)
- EOD Adam: 3 rows (aadc, gpu, cpp)
- EOD Brute-Force: 1 row (bf)
- **Total: up to 23 rows per run** (22 without exclusions on a machine with all backends)

### C++ AADC Backend

The C++ binary (`build/simm_optimizer`) supports both GD and Adam optimization via `--method`. The Python workflow invokes it with `--mode all` for each method:

1. **GD run**: `simm_optimizer --mode all --method gradient_descent --input-dir <shared_data>` — parses attribution, whatif, pretrade, and GD optimize
2. **Adam run**: `simm_optimizer --mode all --method adam --input-dir <shared_data>` — only optimize section used (attribution/whatif/pretrade identical)

Both runs share the same exported sensitivity matrix and allocation from the Python workflow (`data/shared_benchmark_data/`), ensuring apples-to-apples comparison.

### C++ Adam Optimizer (`allocation_optimizer.h`)

The C++ Adam implementation (lines 604-733) uses:
- Hyperparameters: β1=0.9, β2=0.999, ε=1e-8
- Bias-corrected moments: m̂ = m/(1-β1^t), v̂ = v/(1-β2^t)
- Adaptive step: lr × m̂ / (√v̂ + ε)
- Backtracking line search on final step (β=0.5, up to 10 retries)
- Early stopping after 20 consecutive stalling iterations
- Simplex projection per row (sum=1, all≥0)
- Greedy refinement on integer allocation (top-k gradient-guided moves)

### Note: Trade Count vs `--trades` Argument

The number of trades in the sensitivity matrix S may be slightly less than the `--trades` value. This is expected behavior: during CRIF computation (`precompute_all_trade_crifs()`), each trade's sensitivities are evaluated via the AADC kernel, and any sensitivity with `abs(value) <= 1e-10` is dropped. If **all** of a trade's sensitivities fall below this threshold, the trade is excluded from the S matrix entirely since it contributes nothing to SIMM margin. For example, `--trades 1000` might produce `S.shape = (987, K)` if 13 trades have near-zero risk.

### Usage

```bash
source venv/bin/activate

# Default: all 3 methods, all backends
python benchmark_trading_workflow.py --trades 1000 --portfolios 5

# Exclude brute-force
python benchmark_trading_workflow.py --trades 1000 --portfolios 5 --exclude gpu_brute_force

# Exclude Adam and brute-force (GD only)
python benchmark_trading_workflow.py --trades 1000 --portfolios 5 --exclude adam gpu_brute_force

# Quick test with minimal output
python benchmark_trading_workflow.py --trades 100 --portfolios 3 --output none
```

---

## Execution Log Schema: `data/execution_log_portfolio.csv`

Every benchmark run appends rows to this CSV. One row per backend per step (or per optimization method). Archived logs are suffixed by date (e.g., `execution_log_portfolio_Feb2.csv`).

### Identity & Configuration

| Column | Type | Description |
|--------|------|-------------|
| `timestamp` | ISO 8601 | When this row was logged (e.g., `2026-02-02T17:49:52.716102`) |
| `model_name` | string | Backend + workflow step identifier. Examples: `workflow_portfolio_setup_aadc_full`, `workflow_eod_optimize_gpu_full`, `typical_day_cpp_aadc`. The naming convention is `{script}_{step}_{backend}_{simm_formula}`. |
| `model_version` | string | Semantic version of the benchmark script (e.g., `2.8.0`) |
| `trade_types` | string | Comma-separated trade types in the portfolio (e.g., `ir_swap`, `ir_swap,equity_option,fx_option`) |
| `num_trades` | int | Total number of trades in the portfolio |
| `num_simm_buckets` | int | Number of SIMM buckets across all risk classes (determines GPU kernel dimensions) |
| `num_portfolios` | int | Number of counterparty portfolios (P) |
| `num_threads` | int | AADC/OpenMP thread count used for this run |

### CRIF Timing

| Column | Type | Description |
|--------|------|-------------|
| `crif_time_sec` | float | Time to compute CRIF sensitivities from trade objects (bump-and-revalue or AADC adjoint). Empty for steps that reuse pre-computed CRIF. |
| `crif_kernel_recording_sec` | float | AADC kernel recording time for CRIF computation. Empty for GPU or when CRIF is reused. |

### SIMM Evaluation Timing

| Column | Type | Description |
|--------|------|-------------|
| `simm_time_sec` | float | Wall time for the SIMM margin evaluation(s) in this step. For single-eval steps (attribution, what-if), this is the per-eval time. For multi-eval steps (optimization), this is total eval time across all iterations. |
| `im_sens_time_sec` | float | Time to compute IM + sensitivities (gradients). Same as `simm_time_sec` for steps that compute both IM and dIM/dTrade simultaneously. |
| `im_kernel_recording_sec` | float | One-time AADC kernel recording time for the SIMM formula. The kernel is recorded once per session and reused for all subsequent evaluations. Empty for GPU backend. |

### Portfolio Group

| Column | Type | Description |
|--------|------|-------------|
| `group_id` | string | Portfolio group identifier. `ALL` for aggregate results, or a group index (`0`, `1`, ...) for per-counterparty results. |
| `num_group_trades` | int | Number of trades in this group. Equals `num_trades` when `group_id = ALL`. |
| `im_result` | float | SIMM Initial Margin in USD for this group/step. This is the total IM across all counterparties for `ALL` rows, or per-counterparty IM for indexed groups. |
| `num_im_sensitivities` | int | Number of IM sensitivities computed: `K (risk factors) x P (portfolios)`. Represents the gradient dimensions. |

### Single-Step Reallocation (legacy)

These fields are from the older single-step reallocation benchmark. Empty in workflow and typical-day benchmarks.

| Column | Type | Description |
|--------|------|-------------|
| `reallocate_n` | int | Number of trades considered for reallocation |
| `reallocate_time_sec` | float | Time for the reallocation step |
| `im_before_realloc` | float | Total IM before reallocation ($) |
| `im_after_realloc` | float | Total IM after reallocation ($) |
| `realloc_trades_moved` | int | Number of trades moved to different counterparties |
| `realloc_im_reduction` | float | Absolute IM reduction ($) |
| `realloc_im_reduction_pct` | float | IM reduction as percentage of initial IM |
| `im_realloc_estimate` | float | Gradient-estimated IM after reallocation (for validation) |
| `realloc_estimate_matches` | bool | Whether the gradient estimate matched the actual post-realloc IM |

### Optimization

These fields are populated for EOD optimization steps (gradient descent, Adam, greedy, brute-force).

| Column | Type | Description |
|--------|------|-------------|
| `optimize_method` | string | Optimization algorithm: `gradient_descent`, `adam`, `greedy`, `gpu_brute_force` |
| `optimize_time_sec` | float | Total wall time for the optimization run (all iterations) |
| `optimize_initial_im` | float | Total IM before optimization ($) |
| `optimize_final_im` | float | Total IM after optimization ($) |
| `optimize_trades_moved` | int | Number of trades reassigned to different counterparties |
| `optimize_iterations` | int | Number of optimizer iterations completed |
| `optimize_im_reduction_pct` | float | IM reduction as percentage: `(initial - final) / initial * 100` |
| `optimize_converged` | bool | `True` if optimizer stopped before `max_iters` (early convergence) |
| `optimize_max_iters` | int | Maximum iterations allowed for this run |

### Throughput

| Column | Type | Description |
|--------|------|-------------|
| `num_simm_evals` | int | Number of SIMM kernel evaluations performed in this step. For optimization, this is `iterations + 1` (initial + per-iteration). For attribution, this is `1`. |
| `simm_evals_per_sec` | float | Throughput: `num_simm_evals / simm_time_sec`. Key metric for comparing backend raw speed. |

### Status

| Column | Type | Description |
|--------|------|-------------|
| `status` | string | `success` or `error`. All rows in normal operation are `success`. |

### Example `model_name` Values

| model_name | Source Script | Description |
|------------|--------------|-------------|
| `workflow_portfolio_setup_aadc_full` | `benchmark_trading_workflow.py` | Start-of-day portfolio IM via AADC |
| `workflow_portfolio_setup_gpu_full` | `benchmark_trading_workflow.py` | Start-of-day portfolio IM via GPU |
| `workflow_margin_attribution_aadc_full` | `benchmark_trading_workflow.py` | Euler margin decomposition via AADC |
| `workflow_pretrade_aadc_full` | `benchmark_trading_workflow.py` | Intraday pre-trade routing via AADC |
| `workflow_whatif_aadc_full` | `benchmark_trading_workflow.py` | What-if stress scenarios via AADC |
| `workflow_eod_optimize_aadc_full` | `benchmark_trading_workflow.py` | EOD gradient descent optimization via AADC |
| `workflow_eod_optimize_gpu_full` | `benchmark_trading_workflow.py` | EOD gradient descent optimization via GPU |
| `workflow_eod_bf_gpu_full` | `benchmark_trading_workflow.py` | EOD brute-force optimization via GPU |
| `workflow_eod_optimize_cpp_full` | `benchmark_trading_workflow.py` | EOD optimization via C++ AADC |
| `typical_day_aadc_py` | `benchmark_typical_day.py` | AADC Python throughput measurement |
| `typical_day_gpu` | `benchmark_typical_day.py` | GPU throughput measurement |
| `typical_day_bf_gpu` | `benchmark_typical_day.py` | BF GPU throughput measurement |
| `typical_day_cpp_aadc` | `benchmark_typical_day.py` | C++ AADC throughput measurement |

---

## Backend Architecture: What Each Eval Actually Computes (2026-02-02)

### Kernel Recording and Reuse

The AADC kernel is recorded **once** during `setup_portfolio_and_kernel()` (start-of-day). It has K inputs (aggregated sensitivities per risk factor) and 1 output (IM). By passing arrays of length P, a single `aadc.evaluate()` call evaluates all P portfolios simultaneously. **This kernel is never re-recorded** — all 5 workflow steps reuse it.

The GPU has no recording concept. Its CUDA kernels are statically compiled. GPU constants (risk weights, correlations, bucket structure) are pre-allocated on the device once during setup to avoid repeated host-to-device transfers.

C++ AADC records its own kernel inside the subprocess, independently from the Python AADC kernel.

### What Each Backend Returns Per Evaluation

| Backend | Forward (IM) | Gradient (dIM/dS) | Method | Cost |
|---------|-------------|-------------------|--------|------|
| **AADC Python** | Yes (P values) | Yes (K×P matrix) | Adjoint (reverse mode AAD) | O(K×P) |
| **GPU CUDA** | Yes (P values) | Yes (K×P matrix) | Analytical hand-coded chain rule | O(K²×P) |
| **BF GPU** | Yes (P values) | **No** | Forward-only CUDA kernel | O(K²×P), ~50% cheaper than GPU |
| **C++ AADC** | Yes (P values) | Yes (K×P matrix) | Adjoint (reverse mode AAD, compiled) | O(K×P), faster constant factor |

The gradient cost difference is fundamental: AADC computes ALL K gradients in one reverse pass at O(K) cost (the "cheap gradient principle" — adjoint cost ≤ 4× forward cost regardless of K). The GPU kernel computes each gradient at O(K) cost via hand-coded chain rule, but must loop over all K factors, giving O(K²) total.

### Per-Step Computation Detail

#### Step 1: Portfolio Setup
All 4 backends compute initial IM for P portfolios from `agg_S = S.T @ allocation`.
- **AADC/GPU/C++**: 1 eval → IM values + full gradient. Gradient is cached for Step 2.
- **BF GPU**: 1 eval → IM values only. No gradient to cache.

#### Step 2: Margin Attribution
Euler decomposition: `contribution[t] = S[t,:] · grad[portfolio(t),:]`
- **AADC Python**: **Zero new evaluations.** Reuses gradient cached from Step 1. Cost is a numpy dot product (microseconds to low milliseconds).
- **GPU**: **Zero new evaluations.** Same — reuses cached `gpu_grads`. Pure numpy.
- **BF GPU**: **Cannot reuse** (no cached gradient). Instead does bump-and-revalue: removes each trade one at a time and recomputes IM. All T removals are batched into a **single GPU launch** (T rows of modified `agg_S`). Cost = 1 batched forward eval over T configurations.
- **C++**: Computes attribution in the same subprocess invocation as Step 1. Time is shared.

**If market data changes intraday** (repricing), attribution needs fresh gradients. AADC/GPU re-evaluate the existing kernel with new inputs (no re-recording). Cost:

| Backend | Re-evaluation for new market data |
|---------|----------------------------------|
| AADC Py | 1 `aadc.evaluate()` call, 1–17ms depending on K |
| GPU | 1 CUDA kernel launch, ~0.7ms fixed + O(K²×P) compute |
| BF GPU | 1 batched forward launch over T configs |
| C++ | 1 subprocess eval, 2–6ms |

#### Step 3: Intraday Pre-Trade
Route N new trades to optimal portfolios using marginal IM.
- **AADC/GPU**: Compute gradient, then `marginal_IM = grad @ s_new` (O(K) per trade). Refresh gradient every 10 trades. **5 gradient evaluations** for 50 trades.
- **BF GPU**: No gradient available. Must explicitly evaluate `IM(portfolio + trade)` for every trade × every portfolio candidate. **100 forward-only evaluations** (2 per trade × 50 trades). Each eval is cheaper (no gradient), but 20× more are needed.
- **C++**: Same gradient-based approach as AADC Py. 1 evaluation covers all new trades.

#### Step 4: What-If Scenarios
4 scenarios (stress rates, unwind top contributors, add hedge, IM ladder at 5 shock levels) = 8 evaluations.
- **AADC Python**: Uses AAD — **not** bump-and-revalue. Each scenario modifies `agg_S` and calls `aadc.evaluate()` once, getting both stressed IM and full gradient in a single forward+adjoint pass. The gradient tells you **which risk factors drive the scenario impact**.
- **GPU**: Same 8 evaluations, analytical gradient per eval. Also returns risk factor decomposition.
- **BF GPU**: Same 8 evaluations, forward-only. Returns **only the scalar IM** per scenario — cannot decompose the scenario impact by risk factor.
- **C++**: 4 evaluations (batches scenarios in pairs). Returns IM + gradient.

#### Step 5: EOD Optimization
- **Adam/GD (AADC, GPU, C++)**: Phase 1 continuous optimization + Phase 2 greedy local search. Every iteration calls the gradient function. AADC kernel reuse throughout — zero re-recordings.
- **BF GPU**: Evaluates ALL T×(P-1) candidate single-trade moves per round in one massive GPU launch. Forward-only, no gradient needed. Picks globally best move per round.

### GPU CUDA Is an Independent Implementation, Not AADC

The GPU backend (`model/simm_portfolio_cuda.py`) implements the SIMM formula and its analytical derivatives in a **hand-written CUDA kernel** (`_simm_gradient_kernel_full`). It does NOT use AADC. The gradient is computed via manually derived chain rule:

```
dIM/dS_k = dIM/d(rc_margin) × d(margin)/d(WS_k) × RW_k × CR_k
```

The fact that AADC Python and GPU produce **bit-identical** results (matching to 16 significant figures) is because:
1. Both implement the same ISDA SIMM v2.6 formula
2. Both use the same risk weights, correlations, and concentration factors
3. Both operate on the same `agg_S = S.T @ allocation`
4. IEEE 754 double precision is deterministic for the same operation sequence

This serves as a **strong cross-validation**: two completely independent implementations (one auto-differentiated, one hand-coded) arriving at identical results confirms both are correct. The C++ AADC backend shows small differences (0.001–0.01% in IM) because its kernel records and evaluates with slightly different floating-point operation ordering.

**Summary: 3 independent SIMM implementations, 2 agree exactly (AADC Py ↔ GPU), 1 agrees to 4–5 significant figures (C++).**

---

## Throughput: Apples-to-Apples Comparison (2026-02-02)

### The Problem with Raw evals/sec

The `simm_evals_per_sec` column in the CSV is **not directly comparable** across backends because each "eval" computes different amounts of work:

| Backend | What 1 eval computes | Relative work |
|---------|---------------------|---------------|
| AADC Py | IM for P portfolios + full K×P gradient matrix | 1.0× (baseline) |
| GPU | IM for P portfolios + full K×P gradient matrix | ~1.0× (same outputs, different method) |
| BF GPU | IM for P portfolios, **no gradient** | ~0.5× (forward-only) |
| C++ | IM for P portfolios + full K×P gradient matrix | ~1.0× (same as AADC Py) |

BF GPU's throughput numbers look comparable to AADC/GPU in some steps, but each BF eval produces **half the information** (no risk factor decomposition).

### The Downstream Cost of Missing Gradients

Because BF lacks gradients, it compensates by running **more evaluations** to reach the same decision:

| Step | AADC/GPU evals | BF GPU evals | BF overhead | Why |
|------|---------------|-------------|-------------|-----|
| 1 (Setup) | 1 | 1 | 1× | Both compute IM only; gradient is a bonus |
| 2 (Attribution) | **0** (cached grad) | **1** (T-row batch) | ∞ | Gradient makes attribution free |
| 3 (Pre-Trade, 50 trades) | 5 | 100 | **20×** | Must try every portfolio for each trade |
| 4 (What-If) | 8 | 8 | 1× | Same eval count, but BF loses risk decomposition |
| 5 (EOD, T=4000) | 11,150 | 101 rounds* | — | Different algorithms, not comparable |

*Each BF round internally evaluates T×(P-1) candidates in one GPU launch, so the 101 "rounds" represent ~101 × 4000 × 14 = 5.7M forward SIMM evaluations batched into GPU launches.

### Fair Metric: Time-to-Decision

The meaningful comparison is wall-clock time to reach the **same business decision**:

| Step | Decision | AADC Py | GPU | BF GPU | C++ |
|------|----------|---------|-----|--------|-----|
| 1 | "What is our IM?" | 1–2ms | 650–720ms | 320ms | 2–6ms |
| 2 | "Which trades drive IM?" | **0ms** (cached) | **0ms** (cached) | 0.7–7ms | shared w/ Step 1 |
| 3 | "Where to route this trade?" | 1.8ms/trade | 5.5ms/trade | 62ms/trade | 0.9ms/trade |
| 4 | "What if rates move +50bp?" | 1.6ms/scenario | 5.4ms/scenario | 3ms/scenario | 3.9ms/scenario |
| 5 | "Optimal EOD reallocation" | 18.7s | 62.4s | 14.0s | 0.7s |

*(T=4000, P=15 run for Steps 3–5)*

---

## The BF GPU Gradient Gap: Trading Implications (2026-02-02)

### What Gradients Give You That Forward-Only Cannot

When AADC or GPU computes `aadc.evaluate()` or the CUDA gradient kernel, the output includes:
- **IM values**: Total initial margin per portfolio (scalar × P)
- **Gradient matrix**: dIM/dS — how each of K risk factors in each of P portfolios contributes to IM (K × P matrix)

BF GPU returns only the IM values. The gradient matrix enables three capabilities that BF fundamentally cannot provide:

#### 1. Instantaneous Attribution (Step 2)

With gradient cached from Step 1, Euler attribution is a **free numpy dot product**:
```
contribution[t] = S[t,:] · grad[portfolio(t),:]
```

| | With gradient | Without gradient (BF) |
|-|---------------|----------------------|
| Method | Dot product on cached grad | Leave-one-out: remove each trade, recompute IM |
| Cost | O(K) per trade, ~microseconds | O(K²) per trade in GPU, needs full eval |
| Batch | Instant (numpy matmul) | 1 GPU launch for all T rows |
| **At T=4000** | **0ms** (already computed) | **7.2ms** (batched forward eval) |
| **At T=8000** | **0ms** | **2.8ms** |

The gradient approach is not just faster — it's mathematically exact (Euler decomposition satisfies the adding-up property: contributions sum to total IM). BF's leave-one-out is an approximation that doesn't sum correctly when trades interact non-linearly.

#### 2. Marginal IM for Trade Routing (Step 3)

With gradient, routing a new trade is a single dot product:
```
marginal_IM[p] = grad[p,:] · s_new[:]    # O(K) per portfolio
best_portfolio = argmin(marginal_IM)       # O(P)
```

Without gradient, BF must evaluate IM for each candidate placement:
```
for p in range(P):
    candidate_IM[p] = forward_eval(agg_S[p,:] + s_new[:])    # O(K²) per portfolio
```

From existing benchmark data at T=4000, P=15:

| Metric | Gradient-based (AADC) | Forward-only (BF) |
|--------|----------------------|-------------------|
| Evals for 50 trades | 5 (refresh every 10) | 100 (2 per trade) |
| Wall time | 9.2ms | **308ms** (33× slower) |
| Per-trade latency | 0.18ms | **6.2ms** |
| Information per eval | IM + full gradient | IM only |

At T=8000, P=15: AADC takes 4.4ms (5 evals) vs BF 103ms (100 evals) — **23× slower**.

For a trading desk routing trades in real-time, 0.18ms vs 6.2ms per trade is the difference between instant feedback and perceptible delay at high trade volumes.

#### 3. Risk Factor Decomposition in Scenarios (Step 4)

This is the most significant qualitative gap. When running what-if scenarios, the gradient tells you **why** the IM changed, not just **how much**:

**With gradient (AADC/GPU)**: "Stressing rates +50bp increases IM by $2.1T. The top drivers are: USD 10Y (+$800B), EUR 5Y (+$450B), JPY 30Y (+$320B). The FX component is offsetting by -$200B."

**Without gradient (BF)**: "Stressing rates +50bp increases IM by $2.1T."

Both agree on the total impact. But only the gradient-based backends can decompose it. This matters for:

| Trading decision | Needs decomposition? | BF sufficient? |
|-----------------|---------------------|----------------|
| "Is this scenario within limits?" | No — just compare scalar | **Yes** |
| "Which desk is driving the increase?" | Yes — need per-bucket attribution | **No** |
| "What hedge reduces the impact most?" | Yes — need gradient direction | **No** |
| "Report top 5 risk drivers to risk committee" | Yes — need ranked factor contributions | **No** |

From existing data, all backends do the same 8 evaluations for what-if. The time difference is small (12.6ms AADC vs 24.4ms BF at T=4000). But AADC returns 8 × K × P = 8 × 2550 × 15 = 306,000 gradient values alongside the 8 IM numbers. BF returns only the 8 IM numbers — a **38,000× information ratio** per unit of compute.

### Quantified Impact Across All Steps

Using T=4000, P=15, K=2550 run data:

| Step | AADC Py time | BF GPU time | BF/AADC ratio | Information loss |
|------|-------------|-------------|---------------|-----------------|
| 1 Setup | 2.3ms | 319ms | 139× slower | No gradient for downstream steps |
| 2 Attribution | **0ms** | 7.2ms | ∞ | Approximate (leave-one-out) vs exact (Euler) |
| 3 Pre-Trade | 9.2ms | 308ms | **33× slower** | No marginal IM shortcut |
| 4 What-If | 12.6ms | 24.4ms | 1.9× slower | **No risk factor decomposition** |
| 5 EOD | 18.7s | 14.0s | 0.75× (BF faster) | Finds slightly better solution (+1.8pp) |

**BF wins only at Step 5** (EOD optimization), where the brute-force search over all T×(P-1) candidates with forward-only eval is a natural GPU workload. For Steps 1–4, the lack of gradients is a consistent disadvantage in both speed and information content.

### When BF GPU Is the Right Choice

Despite the gradient gap, BF GPU has legitimate use cases:

1. **EOD validation**: Run BF overnight as a cross-check against Adam's solution. BF explores a different search space (all discrete moves vs gradient-guided) and may find solutions Adam misses due to non-convexity.

2. **Gradient-free environments**: If AADC is unavailable (licensing, platform constraints), BF GPU is the only option that scales to large portfolios. The forward-only kernel is simpler to implement and maintain.

3. **Audit trail**: BF's search is fully enumerable — every candidate move and its IM impact can be logged. Gradient-based optimization is harder to explain to regulators ("the adjoint tape said this trade should move").

4. **Small P, large T**: When P ≤ 5, BF's per-candidate cost is low (only 2 portfolios change per move) and the GPU can evaluate all T×(P-1) candidates in one launch efficiently.

---

## Scaling Analysis Framework (2026-02-02)

### Dimensions That Affect Performance

| Dimension | Symbol | What it controls | Typical range |
|-----------|--------|-----------------|---------------|
| Trade count | T | Size of sensitivity matrix S (T×K) | 100–10,000 |
| Portfolio count | P | Number of SIMM evaluations per eval call | 3–30 |
| Risk factor count | K | AADC kernel size, SIMM intra-bucket cost | 60–2,550 |
| Thread count | threads | AADC/C++ parallelism (GPU unaffected) | 1–16 |
| Product mix | trade_types | Determines K via distinct risk classes/tenors | 1–3 types |
| SIMM buckets | buckets | More currencies/issuers → higher K | 2–5 |

**K is not independent** — it depends on trade_types, simm_buckets, and T (more trades hit more distinct risk factors). The scaling commands below isolate each dimension while holding others constant.

### Benchmark Commands

All series share an anchor point: **T=2000, P=10, ir_swap+fx_option, 3 buckets, 16 threads** so overlapping runs serve as cross-validation.

#### Series A: Trade Count (T)
```bash
source venv/bin/activate
for T in 200 500 1000 2000 4000 8000; do
  python benchmark_trading_workflow.py -t $T -p 10 \
    --trade-types ir_swap,fx_option --simm-buckets 3 --threads 16 \
    --optimizer adam --output none
done
```
**Expect**: AADC Py and C++ scale with K (which grows sub-linearly with T). GPU/BF have fixed CUDA overhead at small T, then scale with K²×P.

#### Series B: Portfolio Count (P)
```bash
for P in 3 5 10 15 20 30; do
  python benchmark_trading_workflow.py -t 2000 -p $P \
    --trade-types ir_swap,fx_option --simm-buckets 3 --threads 16 \
    --optimizer adam --output none
done
```
**Expect**: All backends scale linearly with P for Steps 1–4 (P independent SIMM evals). EOD scales super-linearly (more portfolios = more candidate moves = more evals).

#### Series C: Product Mix (K)
```bash
python benchmark_trading_workflow.py -t 2000 -p 10 --trade-types ir_swap --simm-buckets 3 --threads 16 --optimizer adam --output none
python benchmark_trading_workflow.py -t 2000 -p 10 --trade-types ir_swap,fx_option --simm-buckets 3 --threads 16 --optimizer adam --output none
python benchmark_trading_workflow.py -t 2000 -p 10 --trade-types ir_swap,equity_option --simm-buckets 3 --threads 16 --optimizer adam --output none
python benchmark_trading_workflow.py -t 2000 -p 10 --trade-types ir_swap,equity_option,fx_option --simm-buckets 3 --threads 16 --optimizer adam --output none
```
**Expect**: Adding product classes increases K substantially. GPU (O(K²)) should degrade faster than AADC (O(K)). BF (O(K²) but no gradient) should track GPU's forward cost.

#### Series D: Thread Count
```bash
for TH in 1 2 4 8 16; do
  python benchmark_trading_workflow.py -t 2000 -p 10 \
    --trade-types ir_swap,fx_option --simm-buckets 3 --threads $TH \
    --optimizer adam --output none
done
```
**Expect**: AADC Py and C++ scale with threads (AADC kernel releases GIL). GPU/BF unaffected (single GPU stream). C++ should show better thread scaling than Python due to no GIL contention.

#### Series E: Bucket Count (K at fixed T)
```bash
for B in 2 3 5; do
  python benchmark_trading_workflow.py -t 2000 -p 10 \
    --trade-types ir_swap,fx_option --simm-buckets $B --threads 16 \
    --optimizer adam --output none
done
```
**Expect**: More buckets = more currencies = higher K at the same T. Isolates K's effect from T's effect.

### Existing Data: Preliminary Scaling Observations

From the 6 runs already in `execution_log_portfolio.csv`:

**K is the primary cost driver, not T:**
- T=8000, K=990: AADC EOD = 28.4s
- T=4000, K=2550: AADC EOD = 18.7s (fewer trades but higher K... yet faster?)
- Actually T=8000 does 26,473 evals vs T=4000 doing 11,150 — the per-eval cost at K=990 is 1.07ms vs 1.68ms at K=2550. **K drives per-eval cost.**

**GPU degrades quadratically with K:**
- K=60: GPU EOD = 87ms for 107 evals → 0.81ms/eval
- K=990: GPU EOD = 45.9s for 26,473 evals → 1.73ms/eval (2.1×)
- K=2550: GPU EOD = 62.4s for 11,150 evals → 5.60ms/eval (6.9×)
- K ratio 2550/60 = 42.5×. Eval cost ratio 5.60/0.81 = 6.9×. Expected O(K²) ratio = 42.5² ÷ some constant. The sub-quadratic actual scaling suggests GPU parallelism partially compensates.

**C++ throughput improves with scale:**
- T=100: 71,429 evals/s
- T=4000: 15,959 evals/s
- T=8000: 33,131 evals/s
- The incremental greedy approach means per-candidate cost is O(K) regardless of T. Higher T means more productive moves per round, so fewer wasted evaluations.

**Total runs needed: 25** (6 in Series A + 6 in B + 4 in C + 5 in D + 3 in E, minus 1 duplicate at anchor point). Each produces ~20 CSV rows → ~500 new data points for systematic scaling analysis.

---

## Latest Results: v2.9.0 (2026-02-02)

### Configuration

| Parameter | Value |
|-----------|-------|
| Version | 2.9.0 |
| Trades | 4,000 |
| Trade types | ir_swap, fx_option |
| SIMM buckets | 5 |
| Portfolios | 15 |
| Risk factors (K) | 2,550 |
| AADC/C++ threads | 16 |

### Step 1: Portfolio Setup (1 SIMM eval)

| Backend | SIMM Time (s) | Evals/sec | IM Match |
|---------|---------------|-----------|----------|
| AADC Python (16T) | 0.0023 | **430** | Baseline |
| GPU CUDA | 0.715 | 1.4 | Yes |
| GPU Brute-Force | 0.318 | 3.1 | Yes |
| C++ AADC (16T) | 0.0057 | 175 | Yes |

AADC Python is **307× faster** than GPU CUDA and **138× faster** than GPU brute-force for initial portfolio setup.

### Step 2: Margin Attribution (1 eval)

| Backend | SIMM Time (s) | Evals/sec |
|---------|---------------|-----------|
| AADC Python | 0.0027 | 373 |
| GPU CUDA | 0.0018 | **550** |
| GPU Brute-Force | 0.0071 | 141 |
| C++ AADC | 0.0057 | 175 |

GPU CUDA is **1.5× faster** than AADC for single attribution eval. Both AADC and GPU reuse cached gradients from Step 1 — the time here is pure numpy dot-product overhead, not kernel re-evaluation.

### Step 3: Intraday Pre-Trade (5 evals)

| Backend | SIMM Time (s) | Evals/sec |
|---------|---------------|-----------|
| AADC Python | 0.0089 | **565** |
| GPU CUDA | 0.0275 | 182 |
| GPU Brute-Force | 0.308 | 325 |
| C++ AADC | 0.0057 | 175 |

AADC Python is **3.1× faster** than GPU CUDA. BF GPU needs 100 forward-only evals (vs 5 gradient evals) due to lacking marginal IM shortcut.

### Step 4: What-If Scenarios (8 evals)

| Backend | SIMM Time (s) | Evals/sec |
|---------|---------------|-----------|
| AADC Python | 0.0127 | **629** |
| GPU CUDA | 0.0430 | 186 |
| GPU Brute-Force | 0.0243 | 329 |
| C++ AADC | 0.0040 | **993** |

C++ AADC leads at 993 evals/sec. AADC Python is **3.4× faster** than GPU CUDA. Note: C++ runs fewer evals (batches scenarios in pairs).

### Step 5: EOD Optimization — Adam (~11K SIMM evals)

| Backend | Total Time (s) | Evals/sec | IM Reduction % | Converged |
|---------|----------------|-----------|----------------|-----------|
| AADC Python (16T) | 10.63 | **1,049** | 59.3% | Yes (iter 99) |
| GPU CUDA | 33.92 | 329 | 59.3% | Yes (iter 99) |
| C++ AADC (16T) | 0.72 | **15,574** | 59.3% | Yes (iter 101) |
| GPU Brute-Force | 14.11 | 7.2 | 61.2% | No (100 rounds) |

This is where throughput differences are most pronounced:
- **C++ AADC is 47× faster** than GPU CUDA and **15× faster** than AADC Python
- **AADC Python is 3.2× faster** than GPU CUDA
- GPU Brute-Force achieves slightly better IM reduction (61.2% vs 59.3%) but at **2,163× fewer evals/sec** than C++ AADC

### Peak Throughput Summary

| Backend | Peak evals/sec | Best step | Threads |
|---------|---------------|-----------|---------|
| C++ AADC | **15,574** | EOD (Adam) | 16 |
| AADC Python | 1,049 | EOD (Adam) | 16 |
| GPU CUDA | 550 | Attribution | 1 (GPU) |
| GPU Brute-Force | 329 | What-If | 1 (GPU) |

### Time-to-Decision (wall clock)

| Step | Business Question | AADC Py | GPU CUDA | BF GPU | C++ AADC |
|------|-------------------|---------|----------|--------|----------|
| 1 Setup | "What is our IM?" | **2.3ms** | 715ms | 318ms | 5.7ms |
| 2 Attribution | "Which trades drive IM?" | **2.7ms** | 1.8ms | 7.1ms | 5.7ms |
| 3 Pre-Trade | "Where to route 50 trades?" | **8.9ms** | 27.5ms | 308ms | 5.7ms |
| 4 What-If | "Impact of 8 scenarios?" | 12.7ms | 43.0ms | 24.3ms | **4.0ms** |
| 5 EOD Adam | "Optimal reallocation?" | 10.6s | 33.9s | 14.1s | **0.72s** |

### Key Takeaways (v2.9.0)

1. **C++ AADC dominates at scale**: 15,574 evals/sec in EOD optimization — 47× faster than GPU CUDA, enabled by compiled AADC kernels + OpenMP threading.

2. **AADC Python is the best interactive backend**: Fastest for Steps 1–3 (setup, attribution, pre-trade routing) where sub-10ms latency matters.

3. **GPU CUDA is competitive only for attribution**: Where both backends reuse cached gradients and the comparison is pure numpy overhead, GPU edges ahead. For all other steps, GPU's O(K²) gradient cost at K=2550 is a significant disadvantage.

4. **GPU Brute-Force trades speed for solution quality**: 61.2% IM reduction vs 59.3% for gradient-based methods, but at 2000× lower throughput. Best used as overnight validation or when AADC is unavailable.

5. **Gradient advantage is decisive for intraday workflows**: Steps 1–4 complete in **27ms total** on AADC Python vs **787ms** on GPU CUDA — a **29× end-to-end advantage** for the interactive portion of the trading day.
